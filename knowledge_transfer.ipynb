{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITM2z2zRlWeW",
        "outputId": "83ece888-ce27-456d-ba15-82608d9bb2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [0], Loss: 2.2960\n",
            "Starting epoch 2\n",
            "Epoch [2/5], Batch [0], Loss: 1.6589\n",
            "Starting epoch 3\n",
            "Epoch [3/5], Batch [0], Loss: 1.3132\n",
            "Starting epoch 4\n",
            "Epoch [4/5], Batch [0], Loss: 0.8647\n",
            "Starting epoch 5\n",
            "Epoch [5/5], Batch [0], Loss: 0.7732\n",
            "Accuracy of the model on the test images: 67.00%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "# 1. Kontrola dostupnosti GPU a nastavení zařízení\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# 2. Načtení předtrénovaného modelu\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 3. Odstranění poslední vrstvy a přizpůsobení modelu pro naše třídy (např. 10 tříd)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# 4. Přesun modelu na GPU\n",
        "model.to(device)\n",
        "\n",
        "# 5. Nastavení datových transformací\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 6. Načtení datasetu CIFAR-10\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 7. Zamíchání dat\n",
        "def shuffle_and_select(dataset, num_samples):\n",
        "    # Získání indexů a zamíchání\n",
        "    indices = np.arange(len(dataset))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    selected_indices = []\n",
        "    class_counts = {i: 0 for i in range(10)}  # Počítání vzorků pro každou třídu\n",
        "\n",
        "    for idx in indices:\n",
        "        label = dataset.targets[idx]\n",
        "        if class_counts[label] < num_samples // 10:  # Zajištění vyrovnaného počtu vzorků pro každou třídu\n",
        "            selected_indices.append(idx)\n",
        "            class_counts[label] += 1\n",
        "\n",
        "        if len(selected_indices) >= num_samples:\n",
        "            break\n",
        "\n",
        "    return Subset(dataset, selected_indices)\n",
        "\n",
        "# 8. Vybrání podmnožin tréninkového a testovacího datasetu\n",
        "train_subset = shuffle_and_select(train_dataset, 1000)  # 1000 vzorků pro trénink\n",
        "test_subset = shuffle_and_select(test_dataset, 200)  # 200 vzorků pro testování\n",
        "\n",
        "# 9. Vytvoření DataLoaderů\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "# 10. Ztrátová funkce a optimalizátor\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 11. Mrazení prvních vrstev (volitelné)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 12. Tréninková smyčka\n",
        "num_epochs = 5\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch + 1}')\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)  # Přesun dat na GPU\n",
        "        optimizer.zero_grad()  # Vyčištění gradientů\n",
        "        outputs = model(images)  # Predikce\n",
        "        loss = criterion(outputs, labels)  # Výpočet ztráty\n",
        "        loss.backward()  # Výpočet gradientů\n",
        "        optimizer.step()  # Aktualizace parametrů\n",
        "\n",
        "        if i % 100 == 0:  # Každých 100 batchů\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{i}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# 13. Vyhodnocení modelu\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Přesun dat na GPU\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')\n",
        "\n"
      ]
    }
  ]
}